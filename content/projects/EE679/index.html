---
layout: single
author_profile: true
---

<h1>Automatic Spoken Word Recognition</h1>

<div class="image-in-text">
    <img src="./../thumbnail_ismir2022.png" alt="Genre classification image">
  </div>

<h4>Codes:</h4>
<a href="https://github.com/Shreyas789/EE679-Speech-Processing/tree/main">GITHUB</a> (repo containing all assignments in the course)</h6>
<br>
<a href="https://github.com/Shreyas789/EE679-Speech-Processing/blob/main/Assignment-3-Feature_Extraction.ipynb">Feature Extraction Notebook</a> (This project, Asgn 3)
<br>
<a href="https://github.com/Shreyas789/EE679-Speech-Processing/blob/main/Assignment-3-Digit_Recognition.ipynb">Word Recognition Notebook</a> (This project, Asgn 3)

<br><br>

<b>Python libraries used</b>: Hmmlearn, Librosa, Soundfile, Pandas, Numpy
<br><br>



<!-- <b>Other Software used</b>: Audacity, Praat

<p>This was a Summer Undergraduate Research Project (SURP) which I had done under Prof. Preeti Rao, EE, IITB. It got published as a <b>Late-Breaking Demo (LBD)</b>, a forum for early research results and prototype systems in <a href="https://ismir2022.ismir.net/"><b>ISMIR 2022</b></a>.</p>

<p>Genre classification models were trained using Support Vector Machines (SVMs) between three forms of Marathi vocal music each with a distinct socio-cultural context: devotional (Bhaktigeet), poetic (Bhavgeet) and folk dance (Lavani) were. A dataset of over 150 songs (around 50 per genre) was constructed from Youtube videos. We used timbre and chroma based features, such as spectral centroid, spectral bandwidth, MFCC and zero crossing rate for the 3-way classification. Special attention was given to whether the source-separated vocal and instrumental accompaniment components can help improve genre recognition accuracy over that obtained with acoustic features extracted from the original mix audio track.</p>

<p>To know more, please check out our <a href="https://ismir2022program.ismir.net/lbd_365.html">paper</a>.</p> -->
